{"ast":null,"code":"import { Trie } from \"@wry/trie\";\nimport { StrongCache } from \"@wry/caches\";\nimport { Entry } from \"./entry.js\";\nimport { parentEntrySlot } from \"./context.js\"; // These helper functions are important for making optimism work with\n// asynchronous code. In order to register parent-child dependencies,\n// optimism needs to know about any currently active parent computations.\n// In ordinary synchronous code, the parent context is implicit in the\n// execution stack, but asynchronous code requires some extra guidance in\n// order to propagate context from one async task segment to the next.\n\nexport { bindContext, noContext, nonReactive, setTimeout, asyncFromGen, Slot } from \"./context.js\"; // A lighter-weight dependency, similar to OptimisticWrapperFunction, except\n// with only one argument, no makeCacheKey, no wrapped function to recompute,\n// and no result value. Useful for representing dependency leaves in the graph\n// of computation. Subscriptions are supported.\n\nexport { dep } from \"./dep.js\"; // The defaultMakeCacheKey function is remarkably powerful, because it gives\n// a unique object for any shallow-identical list of arguments. If you need\n// to implement a custom makeCacheKey function, you may find it helpful to\n// delegate the final work to defaultMakeCacheKey, which is why we export it\n// here. However, you may want to avoid defaultMakeCacheKey if your runtime\n// does not support WeakMap, or you have the ability to return a string key.\n// In those cases, just write your own custom makeCacheKey functions.\n\nlet defaultKeyTrie;\nexport function defaultMakeCacheKey() {\n  const trie = defaultKeyTrie || (defaultKeyTrie = new Trie(typeof WeakMap === \"function\"));\n\n  for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n    args[_key] = arguments[_key];\n  }\n\n  return trie.lookupArray(args);\n} // If you're paranoid about memory leaks, or you want to avoid using WeakMap\n// under the hood, but you still need the behavior of defaultMakeCacheKey,\n// import this constructor to create your own tries.\n\nexport { Trie as KeyTrie };\n;\nconst caches = new Set();\nexport function wrap(originalFunction) {\n  let {\n    max = Math.pow(2, 16),\n    keyArgs,\n    makeCacheKey = defaultMakeCacheKey,\n    normalizeResult,\n    subscribe,\n    cache: cacheOption = StrongCache\n  } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : Object.create(null);\n  const cache = typeof cacheOption === \"function\" ? new cacheOption(max, entry => entry.dispose()) : cacheOption;\n\n  const optimistic = function () {\n    const key = makeCacheKey.apply(null, keyArgs ? keyArgs.apply(null, arguments) : arguments);\n\n    if (key === void 0) {\n      return originalFunction.apply(null, arguments);\n    }\n\n    let entry = cache.get(key);\n\n    if (!entry) {\n      cache.set(key, entry = new Entry(originalFunction));\n      entry.normalizeResult = normalizeResult;\n      entry.subscribe = subscribe; // Give the Entry the ability to trigger cache.delete(key), even though\n      // the Entry itself does not know about key or cache.\n\n      entry.forget = () => cache.delete(key);\n    }\n\n    const value = entry.recompute(Array.prototype.slice.call(arguments)); // Move this entry to the front of the least-recently used queue,\n    // since we just finished computing its value.\n\n    cache.set(key, entry);\n    caches.add(cache); // Clean up any excess entries in the cache, but only if there is no\n    // active parent entry, meaning we're not in the middle of a larger\n    // computation that might be flummoxed by the cleaning.\n\n    if (!parentEntrySlot.hasValue()) {\n      caches.forEach(cache => cache.clean());\n      caches.clear();\n    }\n\n    return value;\n  };\n\n  Object.defineProperty(optimistic, \"size\", {\n    get: () => cache.size,\n    configurable: false,\n    enumerable: false\n  });\n  Object.freeze(optimistic.options = {\n    max,\n    keyArgs,\n    makeCacheKey,\n    normalizeResult,\n    subscribe,\n    cache\n  });\n\n  function dirtyKey(key) {\n    const entry = key && cache.get(key);\n\n    if (entry) {\n      entry.setDirty();\n    }\n  }\n\n  optimistic.dirtyKey = dirtyKey;\n\n  optimistic.dirty = function dirty() {\n    dirtyKey(makeCacheKey.apply(null, arguments));\n  };\n\n  function peekKey(key) {\n    const entry = key && cache.get(key);\n\n    if (entry) {\n      return entry.peek();\n    }\n  }\n\n  optimistic.peekKey = peekKey;\n\n  optimistic.peek = function peek() {\n    return peekKey(makeCacheKey.apply(null, arguments));\n  };\n\n  function forgetKey(key) {\n    return key ? cache.delete(key) : false;\n  }\n\n  optimistic.forgetKey = forgetKey;\n\n  optimistic.forget = function forget() {\n    return forgetKey(makeCacheKey.apply(null, arguments));\n  };\n\n  optimistic.makeCacheKey = makeCacheKey;\n  optimistic.getKey = keyArgs ? function getKey() {\n    return makeCacheKey.apply(null, keyArgs.apply(null, arguments));\n  } : makeCacheKey;\n  return Object.freeze(optimistic);\n}","map":{"version":3,"mappings":"AAAA,SAASA,IAAT,QAAqB,WAArB;AAEA,SAASC,WAAT,QAAyC,aAAzC;AACA,SAASC,KAAT,QAAgC,YAAhC;AACA,SAASC,eAAT,QAAgC,cAAhC,C,CAGA;AACA;AACA;AACA;AACA;AACA;;AACA,SACEC,WADF,EAEEC,SAFF,EAGEC,WAHF,EAIEC,UAJF,EAKEC,YALF,EAMEC,IANF,QAOO,cAPP,C,CASA;AACA;AACA;AACA;;AACA,SAASC,GAAT,QAAkD,UAAlD,C,CAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,IAAIC,cAAJ;AACA,OAAM,SAAUC,mBAAV,GAA4C;AAChD,QAAMC,IAAI,GAAGF,cAAc,KACzBA,cAAc,GAAG,IAAIX,IAAJ,CAAS,OAAOc,OAAP,KAAmB,UAA5B,CADQ,CAA3B;;AADgD,oCAAXC,IAAW;AAAXA,QAAW;AAAA;;AAIhD,SAAOF,IAAI,CAACG,WAAL,CAAiBD,IAAjB,CAAP;AACD,C,CAED;AACA;AACA;;AACA,SAASf,IAAI,IAAIiB,OAAjB;AAqFC;AAED,MAAMC,MAAM,GAAG,IAAIC,GAAJ,EAAf;AAEA,OAAM,SAAUC,IAAV,CAKJC,gBALI,EAY6E;AAAA,MAPlC;AAC/CC,OAAG,GAAGC,IAAI,CAACC,GAAL,CAAS,CAAT,EAAY,EAAZ,CADyC;AAE/CC,WAF+C;AAG/CC,gBAAY,GAAId,mBAH+B;AAI/Ce,mBAJ+C;AAK/CC,aAL+C;AAM/CC,SAAK,EAAEC,WAAW,GAAG7B;AAN0B,GAOkC,uEAAnB8B,MAAM,CAACC,MAAP,CAAc,IAAd,CAAmB;AACjF,QAAMH,KAAK,GACT,OAAOC,WAAP,KAAuB,UAAvB,GACI,IAAIA,WAAJ,CAAgBR,GAAhB,EAAqBW,KAAK,IAAIA,KAAK,CAACC,OAAN,EAA9B,CADJ,GAEIJ,WAHN;;AAKA,QAAMK,UAAU,GAAG;AACjB,UAAMC,GAAG,GAAGV,YAAY,CAACW,KAAb,CACV,IADU,EAEVZ,OAAO,GAAGA,OAAO,CAACY,KAAR,CAAc,IAAd,EAAoBC,SAApB,CAAH,GAA2CA,SAFxC,CAAZ;;AAKA,QAAIF,GAAG,KAAK,KAAK,CAAjB,EAAoB;AAClB,aAAOf,gBAAgB,CAACgB,KAAjB,CAAuB,IAAvB,EAA6BC,SAA7B,CAAP;AACD;;AAED,QAAIL,KAAK,GAAGJ,KAAK,CAACU,GAAN,CAAUH,GAAV,CAAZ;;AACA,QAAI,CAACH,KAAL,EAAY;AACVJ,WAAK,CAACW,GAAN,CAAUJ,GAAV,EAAeH,KAAK,GAAG,IAAI/B,KAAJ,CAAUmB,gBAAV,CAAvB;AACAY,WAAK,CAACN,eAAN,GAAwBA,eAAxB;AACAM,WAAK,CAACL,SAAN,GAAkBA,SAAlB,CAHU,CAIV;AACA;;AACAK,WAAK,CAACQ,MAAN,GAAe,MAAMZ,KAAK,CAACa,MAAN,CAAaN,GAAb,CAArB;AACD;;AAED,UAAMO,KAAK,GAAGV,KAAK,CAACW,SAAN,CACZC,KAAK,CAACC,SAAN,CAAgBC,KAAhB,CAAsBC,IAAtB,CAA2BV,SAA3B,CADY,CAAd,CApBiB,CAwBjB;AACA;;AACAT,SAAK,CAACW,GAAN,CAAUJ,GAAV,EAAeH,KAAf;AAEAf,UAAM,CAAC+B,GAAP,CAAWpB,KAAX,EA5BiB,CA8BjB;AACA;AACA;;AACA,QAAI,CAAE1B,eAAe,CAAC+C,QAAhB,EAAN,EAAkC;AAChChC,YAAM,CAACiC,OAAP,CAAetB,KAAK,IAAIA,KAAK,CAACuB,KAAN,EAAxB;AACAlC,YAAM,CAACmC,KAAP;AACD;;AAED,WAAOV,KAAP;AACiE,GAvCnE;;AAyCAZ,QAAM,CAACuB,cAAP,CAAsBnB,UAAtB,EAAkC,MAAlC,EAA0C;AACxCI,OAAG,EAAE,MAAMV,KAAK,CAAC0B,IADuB;AAExCC,gBAAY,EAAE,KAF0B;AAGxCC,cAAU,EAAE;AAH4B,GAA1C;AAMA1B,QAAM,CAAC2B,MAAP,CAAcvB,UAAU,CAACwB,OAAX,GAAqB;AACjCrC,OADiC;AAEjCG,WAFiC;AAGjCC,gBAHiC;AAIjCC,mBAJiC;AAKjCC,aALiC;AAMjCC;AANiC,GAAnC;;AASA,WAAS+B,QAAT,CAAkBxB,GAAlB,EAA4C;AAC1C,UAAMH,KAAK,GAAGG,GAAG,IAAIP,KAAK,CAACU,GAAN,CAAUH,GAAV,CAArB;;AACA,QAAIH,KAAJ,EAAW;AACTA,WAAK,CAAC4B,QAAN;AACD;AACF;;AACD1B,YAAU,CAACyB,QAAX,GAAsBA,QAAtB;;AACAzB,YAAU,CAAC2B,KAAX,GAAmB,SAASA,KAAT,GAAc;AAC/BF,YAAQ,CAAClC,YAAY,CAACW,KAAb,CAAmB,IAAnB,EAAyBC,SAAzB,CAAD,CAAR;AACD,GAFD;;AAIA,WAASyB,OAAT,CAAiB3B,GAAjB,EAA2C;AACzC,UAAMH,KAAK,GAAGG,GAAG,IAAIP,KAAK,CAACU,GAAN,CAAUH,GAAV,CAArB;;AACA,QAAIH,KAAJ,EAAW;AACT,aAAOA,KAAK,CAAC+B,IAAN,EAAP;AACD;AACF;;AACD7B,YAAU,CAAC4B,OAAX,GAAqBA,OAArB;;AACA5B,YAAU,CAAC6B,IAAX,GAAkB,SAASA,IAAT,GAAa;AAC7B,WAAOD,OAAO,CAACrC,YAAY,CAACW,KAAb,CAAmB,IAAnB,EAAyBC,SAAzB,CAAD,CAAd;AACD,GAFD;;AAIA,WAAS2B,SAAT,CAAmB7B,GAAnB,EAA6C;AAC3C,WAAOA,GAAG,GAAGP,KAAK,CAACa,MAAN,CAAaN,GAAb,CAAH,GAAuB,KAAjC;AACD;;AACDD,YAAU,CAAC8B,SAAX,GAAuBA,SAAvB;;AACA9B,YAAU,CAACM,MAAX,GAAoB,SAASA,MAAT,GAAe;AACjC,WAAOwB,SAAS,CAACvC,YAAY,CAACW,KAAb,CAAmB,IAAnB,EAAyBC,SAAzB,CAAD,CAAhB;AACD,GAFD;;AAIAH,YAAU,CAACT,YAAX,GAA0BA,YAA1B;AACAS,YAAU,CAAC+B,MAAX,GAAoBzC,OAAO,GAAG,SAASyC,MAAT,GAAe;AAC3C,WAAOxC,YAAY,CAACW,KAAb,CAAmB,IAAnB,EAAyBZ,OAAO,CAACY,KAAR,CAAc,IAAd,EAAoBC,SAApB,CAAzB,CAAP;AACD,GAF0B,GAEvBZ,YAFJ;AAIA,SAAOK,MAAM,CAAC2B,MAAP,CAAcvB,UAAd,CAAP;AACD","names":["Trie","StrongCache","Entry","parentEntrySlot","bindContext","noContext","nonReactive","setTimeout","asyncFromGen","Slot","dep","defaultKeyTrie","defaultMakeCacheKey","trie","WeakMap","args","lookupArray","KeyTrie","caches","Set","wrap","originalFunction","max","Math","pow","keyArgs","makeCacheKey","normalizeResult","subscribe","cache","cacheOption","Object","create","entry","dispose","optimistic","key","apply","arguments","get","set","forget","delete","value","recompute","Array","prototype","slice","call","add","hasValue","forEach","clean","clear","defineProperty","size","configurable","enumerable","freeze","options","dirtyKey","setDirty","dirty","peekKey","peek","forgetKey","getKey"],"sources":["/media/rk/disk2/React/crwn-clothing-graphql/node_modules/optimism/src/index.ts"],"sourcesContent":["import { Trie } from \"@wry/trie\";\n\nimport { StrongCache, CommonCache } from \"@wry/caches\";\nimport { Entry, AnyEntry } from \"./entry.js\";\nimport { parentEntrySlot } from \"./context.js\";\nimport type { NoInfer } from \"./helpers.js\";\n\n// These helper functions are important for making optimism work with\n// asynchronous code. In order to register parent-child dependencies,\n// optimism needs to know about any currently active parent computations.\n// In ordinary synchronous code, the parent context is implicit in the\n// execution stack, but asynchronous code requires some extra guidance in\n// order to propagate context from one async task segment to the next.\nexport {\n  bindContext,\n  noContext,\n  nonReactive,\n  setTimeout,\n  asyncFromGen,\n  Slot,\n} from \"./context.js\";\n\n// A lighter-weight dependency, similar to OptimisticWrapperFunction, except\n// with only one argument, no makeCacheKey, no wrapped function to recompute,\n// and no result value. Useful for representing dependency leaves in the graph\n// of computation. Subscriptions are supported.\nexport { dep, OptimisticDependencyFunction } from \"./dep.js\";\n\n// The defaultMakeCacheKey function is remarkably powerful, because it gives\n// a unique object for any shallow-identical list of arguments. If you need\n// to implement a custom makeCacheKey function, you may find it helpful to\n// delegate the final work to defaultMakeCacheKey, which is why we export it\n// here. However, you may want to avoid defaultMakeCacheKey if your runtime\n// does not support WeakMap, or you have the ability to return a string key.\n// In those cases, just write your own custom makeCacheKey functions.\nlet defaultKeyTrie: Trie<object> | undefined;\nexport function defaultMakeCacheKey(...args: any[]): object {\n  const trie = defaultKeyTrie || (\n    defaultKeyTrie = new Trie(typeof WeakMap === \"function\")\n  );\n  return trie.lookupArray(args);\n}\n\n// If you're paranoid about memory leaks, or you want to avoid using WeakMap\n// under the hood, but you still need the behavior of defaultMakeCacheKey,\n// import this constructor to create your own tries.\nexport { Trie as KeyTrie }\n\nexport type OptimisticWrapperFunction<\n  TArgs extends any[],\n  TResult,\n  TKeyArgs extends any[] = TArgs,\n  TCacheKey = any,\n> = ((...args: TArgs) => TResult) & {\n  // Get the current number of Entry objects in the LRU cache.\n  readonly size: number;\n\n  // Snapshot of wrap options used to create this wrapper function.\n  options: OptionsWithCacheInstance<TArgs, TKeyArgs, TCacheKey>;\n\n  // \"Dirty\" any cached Entry stored for the given arguments, marking that Entry\n  // and its ancestors as potentially needing to be recomputed. The .dirty(...)\n  // method of an optimistic function takes the same parameter types as the\n  // original function by default, unless a keyArgs function is configured, and\n  // then it matters that .dirty takes TKeyArgs instead of TArgs.\n  dirty: (...args: TKeyArgs) => void;\n  // A version of .dirty that accepts a key returned by .getKey.\n  dirtyKey: (key: TCacheKey | undefined) => void;\n\n  // Examine the current value without recomputing it.\n  peek: (...args: TKeyArgs) => TResult | undefined;\n  // A version of .peek that accepts a key returned by .getKey.\n  peekKey: (key: TCacheKey | undefined) => TResult | undefined;\n\n  // Completely remove the entry from the cache, dirtying any parent entries.\n  forget: (...args: TKeyArgs) => boolean;\n  // A version of .forget that accepts a key returned by .getKey.\n  forgetKey: (key: TCacheKey | undefined) => boolean;\n\n  // In order to use the -Key version of the above functions, you need a key\n  // rather than the arguments used to compute the key. These two functions take\n  // TArgs or TKeyArgs and return the corresponding TCacheKey. If no keyArgs\n  // function has been configured, TArgs will be the same as TKeyArgs, and thus\n  // getKey and makeCacheKey will be synonymous.\n  getKey: (...args: TArgs) => TCacheKey | undefined;\n\n  // This property is equivalent to the makeCacheKey function provided in the\n  // OptimisticWrapOptions, or (if no options.makeCacheKey function is provided)\n  // a default implementation of makeCacheKey. This function is also exposed as\n  // optimistic.options.makeCacheKey, somewhat redundantly.\n  makeCacheKey: (...args: TKeyArgs) => TCacheKey | undefined;\n};\n\nexport { CommonCache }\nexport interface CommonCacheConstructor<TCacheKey, TResult, TArgs extends any[]> extends Function {\n  new <K extends TCacheKey, V extends Entry<TArgs, TResult>>(max?: number, dispose?: (value: V, key?: K) => void): CommonCache<K,V>;\n}\n\nexport type OptimisticWrapOptions<\n  TArgs extends any[],\n  TKeyArgs extends any[] = TArgs,\n  TCacheKey = any,\n  TResult = any,\n> = {\n  // The maximum number of cache entries that should be retained before the\n  // cache begins evicting the oldest ones.\n  max?: number;\n  // Transform the raw arguments to some other type of array, which will then\n  // be passed to makeCacheKey.\n  keyArgs?: (...args: TArgs) => TKeyArgs;\n  // The makeCacheKey function takes the same arguments that were passed to\n  // the wrapper function and returns a single value that can be used as a key\n  // in a Map to identify the cached result.\n  makeCacheKey?: (...args: NoInfer<TKeyArgs>) => TCacheKey | undefined;\n  // Called when a new value is computed to allow efficient normalization of\n  // results over time, for example by returning older if equal(newer, older).\n  normalizeResult?: (newer: TResult, older: TResult) => TResult;\n  // If provided, the subscribe function should either return an unsubscribe\n  // function or return nothing.\n  subscribe?: (...args: TArgs) => void | (() => any);\n  cache?: CommonCache<NoInfer<TCacheKey>, Entry<NoInfer<TArgs>, NoInfer<TResult>>>\n    | CommonCacheConstructor<NoInfer<TCacheKey>, NoInfer<TResult>, NoInfer<TArgs>>;\n};\n\nexport interface OptionsWithCacheInstance<\n  TArgs extends any[],\n  TKeyArgs extends any[] = TArgs,\n  TCacheKey = any,\n  TResult = any,\n> extends OptimisticWrapOptions<TArgs, TKeyArgs, TCacheKey, TResult> {\n  cache: CommonCache<NoInfer<TCacheKey>, Entry<NoInfer<TArgs>, NoInfer<TResult>>>;\n};\n\nconst caches = new Set<CommonCache<any, AnyEntry>>();\n\nexport function wrap<\n  TArgs extends any[],\n  TResult,\n  TKeyArgs extends any[] = TArgs,\n  TCacheKey = any,\n>(originalFunction: (...args: TArgs) => TResult, {\n  max = Math.pow(2, 16),\n  keyArgs,\n  makeCacheKey = (defaultMakeCacheKey as () => TCacheKey),\n  normalizeResult,\n  subscribe,\n  cache: cacheOption = StrongCache,\n}: OptimisticWrapOptions<TArgs, TKeyArgs, TCacheKey, TResult> = Object.create(null)) {\n  const cache: CommonCache<TCacheKey, Entry<TArgs, TResult>> =\n    typeof cacheOption === \"function\"\n      ? new cacheOption(max, entry => entry.dispose())\n      : cacheOption;\n\n  const optimistic = function (): TResult {\n    const key = makeCacheKey.apply(\n      null,\n      keyArgs ? keyArgs.apply(null, arguments as any) : arguments as any\n    );\n\n    if (key === void 0) {\n      return originalFunction.apply(null, arguments as any);\n    }\n\n    let entry = cache.get(key)!;\n    if (!entry) {\n      cache.set(key, entry = new Entry(originalFunction));\n      entry.normalizeResult = normalizeResult;\n      entry.subscribe = subscribe;\n      // Give the Entry the ability to trigger cache.delete(key), even though\n      // the Entry itself does not know about key or cache.\n      entry.forget = () => cache.delete(key);\n    }\n\n    const value = entry.recompute(\n      Array.prototype.slice.call(arguments) as TArgs,\n    );\n\n    // Move this entry to the front of the least-recently used queue,\n    // since we just finished computing its value.\n    cache.set(key, entry);\n\n    caches.add(cache);\n\n    // Clean up any excess entries in the cache, but only if there is no\n    // active parent entry, meaning we're not in the middle of a larger\n    // computation that might be flummoxed by the cleaning.\n    if (! parentEntrySlot.hasValue()) {\n      caches.forEach(cache => cache.clean());\n      caches.clear();\n    }\n\n    return value;\n  } as OptimisticWrapperFunction<TArgs, TResult, TKeyArgs, TCacheKey>;\n\n  Object.defineProperty(optimistic, \"size\", {\n    get: () => cache.size,\n    configurable: false,\n    enumerable: false,\n  });\n\n  Object.freeze(optimistic.options = {\n    max,\n    keyArgs,\n    makeCacheKey,\n    normalizeResult,\n    subscribe,\n    cache,\n  });\n\n  function dirtyKey(key: TCacheKey | undefined) {\n    const entry = key && cache.get(key);\n    if (entry) {\n      entry.setDirty();\n    }\n  }\n  optimistic.dirtyKey = dirtyKey;\n  optimistic.dirty = function dirty() {\n    dirtyKey(makeCacheKey.apply(null, arguments as any));\n  };\n\n  function peekKey(key: TCacheKey | undefined) {\n    const entry = key && cache.get(key);\n    if (entry) {\n      return entry.peek();\n    }\n  }\n  optimistic.peekKey = peekKey;\n  optimistic.peek = function peek() {\n    return peekKey(makeCacheKey.apply(null, arguments as any));\n  };\n\n  function forgetKey(key: TCacheKey | undefined) {\n    return key ? cache.delete(key) : false;\n  }\n  optimistic.forgetKey = forgetKey;\n  optimistic.forget = function forget() {\n    return forgetKey(makeCacheKey.apply(null, arguments as any));\n  };\n\n  optimistic.makeCacheKey = makeCacheKey;\n  optimistic.getKey = keyArgs ? function getKey() {\n    return makeCacheKey.apply(null, keyArgs.apply(null, arguments as any));\n  } : makeCacheKey as (...args: any[]) => TCacheKey | undefined;\n\n  return Object.freeze(optimistic);\n}\n"]},"metadata":{},"sourceType":"module"}